**Chapitre 8 Applied Statistics** 

**Hypothesis Testing** : Tester sa th√©orie

1 √®re √©tape et 2 √®me √©tape : 

![](D:\Msc2\5DATA\1.1 - Blended Learning  Understanding Data Science ( ~3h)\screens\a.png)

L‚Äôutilisation des tests d‚Äôhypoth√®ses : 

\-    Recherches scientifiques

\-    Diagnostiques 

\-    Le pour et le contre (Go/no go decisions) 

Deux couples d‚Äôhypoth√®ses, **Null Hypothesis** et **Alternative Hypothesis** 

  ![](D:\Msc2\5DATA\1.1 - Blended Learning  Understanding Data Science ( ~3h)\screens\b.png)

Prendre une d√©cision :

\-    M√©thode du faux positif : Echantillon qui montre les effets de fa√ßon al√©atoire 

\-    M√©thode du faux n√©gatif : Les donn√©es semblent al√©atoires (A revoir)

Ces deux m√©thodes sont dangereuses : 

\-    Peuvent facilement √™tre mal interpr√©t√©

\-    Les questions peuvent √™tre mal pos√©es 

 

Conclusion : 

\-    Commun pour la plupart des oui/non questions 

\-    Utiles malgr√© les critiques 

\-    Les estimations sont tr√®s utiles 

**Confidence Intervals** 

 Niveaux de confidences :

\-    Choisir un niveau 

\-    95 % de niveaux communs

\-    Plus de confidence = des intervalles plus libres

Efficacit√© et pr√©cision (Accuracy and precision) 

![](D:\Msc2\5DATA\1.1 - Blended Learning  Understanding Data Science ( ~3h)\screens\c.png)

Interpr√©tation :

  ![](D:\Msc2\5DATA\1.1 - Blended Learning  Understanding Data Science ( ~3h)\screens\d.png)

Facteurs qui affectent les intervalles libres : 

\-    Niveau de confidence 

\-    D√©viation standard

\-    Sample size (plus important) 

Conclusion : 

\-    Les intervalles de confidences sont focus sur les param√®tres 

\-    Les variations sont explicitement incluses 

\-    Plus informatifs que les tests d‚Äôhypoth√®ses 

**Les probl√®mes communs dans la mod√©lisation** 

\-    La non-normalit√© des donn√©es 

o  *Outliers*

o  Mod√®les et mesures distordues 

o  Tentative de transformations

o  Plusieurs distributions ? 

\-    La non-lin√©arit√© des donn√©es 

o  Supposition commune

o  Tentative de transformation de variables 

o  Les polyn√¥mes peuvent aid√©es

\-    Mutlicolin√©arit√© (Bon courage üòä ) 

o  Les pr√©dictions peuvent corr√©l√©es 

o  Les coefficients peuvent √™tre affect√©s 

o  Utilisation de trop de variable 

 

*The combinatorial Explosion and the Curse of dimensionality* 

![](D:\Msc2\5DATA\1.1 - Blended Learning  Understanding Data Science ( ~3h)\screens\e.png)

Les donn√©es manquantes : 

\-    Peuvent cr√©er des distorsions et cr√©er des impartialit√©s 

\-    Chercher les patterns qui manquent 

\-    Ne peut pas remplacer les donn√©es manquantes 

Conclusions :

\-    Les donn√©es apportent des complications 

\-    Les erreurs m√®nent aux ambigu√Øt√©s, l‚Äôimpartialit√©s, les hypoth√®ses

\-    L‚Äôutilisation des analyses et th√©ories peuvent r√©soudre celles-ci 


 

 

**Validating Models** 

Est-ce qu‚Äôon est dans la cible ? 

Les probabilit√©s post√©rieures : 

\-    La plupart des analyses sont de p(DIH)

**-**    Les p(HID) sont plus int√©ressantes [Qim Heart Issues Detector (Qim HID)](https://www.qiminfo.ch/les-projets-data-science-de-qim-info/)

**-**    **Utilisation du th√©or√®me de Bayes** 

R√©plication des √©tudes :

\-    Exact vs conceptual replications 

\-    Combinaisons des r√©sultats d‚Äôautres √©tudes 

\-    Meta-analyse d‚Äôapr√®s la m√©thode Bayesian

Cross validation : 

Les m√™mes donn√©es pour entrainer et tester 

\- Leave-one-out (LOO)

\- Leave-p-out (LPO)

\- k-fold 

Conclusions: 

\-    Permet de faire une *Analysis count* 

\-    Checker la validit√© et la g√©n√©ralisation 

\-    Construire la confidence dans l‚Äôanalyse et le mod√®le 


 

 